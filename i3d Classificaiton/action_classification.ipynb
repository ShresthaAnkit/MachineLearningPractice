{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ankit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the height and width to which each video frame will be resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 128, 128\n",
    "\n",
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "# Specify the directory containing the UCF50 dataset.\n",
    "DATASET_DIR = \"Final_Dataset\"\n",
    "\n",
    "# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n",
    "CLASSES_LIST = [\"Idle\",\"Block\",\"Kicking\",\"Punching\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_webcam(SEQUENCE_LENGTH, convlstm_model):\n",
    "    '''\n",
    "    This function will perform action recognition on a webcam feed using the LRCN model.\n",
    "    Args:\n",
    "    SEQUENCE_LENGTH:  The fixed number of frames of a video that can be passed to the model as one sequence.\n",
    "    IMAGE_HEIGHT:     The height to which each frame is resized.\n",
    "    IMAGE_WIDTH:      The width to which each frame is resized.\n",
    "    convlstm_model:   The pre-trained ConvLSTM model used for prediction.\n",
    "    CLASSES_LIST:     List of class names corresponding to the action classes.\n",
    "    '''\n",
    "\n",
    "    # Initialize the VideoCapture object to read from the webcam.\n",
    "    video_reader = cv2.VideoCapture(0)  # Use 0 for the default webcam\n",
    "\n",
    "    # Declare a queue to store video frames.\n",
    "    frames_queue = deque(maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "    # Initialize a variable to store the predicted action being performed in the video.\n",
    "    predicted_class_name = ''\n",
    "    probs = ''\n",
    "    predicted_labels_probabilities = [0,0,0,0]\n",
    "\n",
    "    # Iterate until the webcam is accessed successfully.\n",
    "    while video_reader.isOpened():\n",
    "        # Read the frame.\n",
    "        ok, frame = video_reader.read()\n",
    "\n",
    "        # Check if frame is not read properly then break the loop.\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        # Resize the frame to fixed dimensions.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "\n",
    "        # Normalize the resized frame by dividing it by 255 so that each pixel value lies between 0 and 1.\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "\n",
    "        # Append the pre-processed frame into the frames queue.\n",
    "        frames_queue.append(normalized_frame)\n",
    "\n",
    "        # Check if the number of frames in the queue are equal to the fixed sequence length.\n",
    "        if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "            # Pass the normalized frames to the model and get the predicted probabilities.\n",
    "            predicted_labels_probabilities = convlstm_model.predict(np.expand_dims(frames_queue, axis=0))[0]\n",
    "            \n",
    "            # Get the index of the class with the highest probability.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "            probs = predicted_labels_probabilities[predicted_label]\n",
    "            # Get the class name using the retrieved index.\n",
    "            predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "            \n",
    "        # Write the predicted class name on top of the frame.\n",
    "        \n",
    "        #cv2.putText(frame, f'{str(predicted_labels_probabilities)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        #cv2.putText(frame, f'{predicted_class_name} {probs}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'{CLASSES_LIST[0]} {predicted_labels_probabilities[0]}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'{CLASSES_LIST[1]} {predicted_labels_probabilities[1]}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'{CLASSES_LIST[2]} {predicted_labels_probabilities[2]}', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'{CLASSES_LIST[3]} {predicted_labels_probabilities[3]}', (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # Display the frame.\n",
    "        cv2.imshow('Webcam Action Recognition', frame)\n",
    "\n",
    "        # Exit the loop when 'q' key is pressed.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object.\n",
    "    video_reader.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model('convlstm_model___Date_Time_2024_07_07__05_16_40___Loss_1.3186445236206055___Accuracy_0.48148149251937866.h5', custom_objects={'ConvLSTM2D': ConvLSTM2D})\n",
    "except ValueError as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model = tf.keras.models.load_model('convlstm_model___Date_Time_2024_07_07__05_16_40___Loss_1.3186445236206055___Accuracy_0.48148149251937866.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('modelv5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_webcam( 20, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
